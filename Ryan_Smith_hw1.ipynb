{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 584 :: Data Mining :: George Mason University :: Fall 2025\n",
    "\n",
    "\n",
    "# Homework 1: KNN&PCA\n",
    "\n",
    "- **100 points [6% of your final grade]**\n",
    "- **Due Tuesday, Sep 28 by 11:59pm**\n",
    "\n",
    "- *Goals of this homework:* (1) implement the KNN algorithm for classifying handwritten digit images; (2) implement the PCA algorithm to reduce the feature dimension so that we can speed up the KNN algorithm and also improve the classification performance; (3) tune the hyperparameters of the KNN and PCA algorithms to produce classification result as good as possible.\n",
    "\n",
    "- *Submission instructions:* for this homework, you should submit your notebook file to **Canvas** (look for the homework 1 assignment there). Please name your submission **FirstName_Lastname_hw1.ipynb**, so for example, my submission would be something like **Ziwei_Zhu_hw1.ipynb**. Your notebook should be fully executed so that we can see all outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: KNN (50 points)\n",
    "\n",
    "In this part, you need to implement your own KNN algorithm for classifying the digits (from 0 to 9) from the handwritten digit images (28 pixels * 28 pixels). The provided train.txt is the training data you will use for building your model. Each line in the file is one sample, whose first value is the ground-truth label, and the following 784 values are the pixels of the image. First of all, let's load the data by executing the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array of labels: shape (60000,)\n",
      "array of feature matrix: shape (60000, 784)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.loadtxt(\"train.txt\", delimiter=',')\n",
    "labels = data[:, 0].astype(int)\n",
    "features = data[:, 1:]\n",
    "print('array of labels: shape ' + str(np.shape(labels)))\n",
    "print('array of feature matrix: shape ' + str(np.shape(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the label variable to store the ground-truth labels (from 0 to 9) of all 60,000 samples, and matrix features to store the image pixels of these samples. Next, let's execute the following code to plot the first 4 samples to see how these images look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x5000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 50))\n",
    "for i in range(4):  \n",
    "    ax[i].imshow(features[i].reshape((28, 28)), cmap=plt.get_cmap('gray'))\n",
    "    ax[i].set_title('Label is %d' % labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to **randomly** select 20% samples (sampling without replacement) from the data as the **validation set**, and generate the new **training set** by removing the selected validation samples from the original dataset. Write your code in the next cell.\n",
    "\n",
    "**Note: You are NOT allowed to directly call APIs from an existing Machine Learning library like sklearn. But you can use the python 'random' library or the random module from 'numpy'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(31) # in case I need to rerun this block, I dont want to accidentaly contaminate the model with overlapping training/validation sets\n",
    "set_index=random.choice(60000,size=3000,replace=False) #generate set index that I will pull from train data and use in validation only\n",
    "validation_labels=labels[set_index] #add set index from train data to validation set\n",
    "validation_features=features[set_index] # add set index from train data to features validation\n",
    "train_labels=np.delete(labels,set_index,axis=0) #remove the random set_index rows from the train data labels so val set is disjoint\n",
    "train_features=np.delete(features,set_index, axis=0) #remove the random set_index rows from the train data features so val set is disjoint\n",
    "\n",
    "#print(len(validation_features[0]))\n",
    "#print(len(train_features[0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to implement your KNN algorithm. In the next cell, please write your code to predict labels for samples in the validation set by the KNN model built on the training set. Here we set K = 10 and use the Euclidean distance to find neighbors.\n",
    "\n",
    "**Note: You should implement the algorithm by Python, Numpy, and other libraries you think are necessary. You are NOT allowed to directly call APIs from an existing Machine Learning library like sklearn.**\n",
    "\n",
    "**Note: Here, you should only use the labels from the training set for the KNN model.**\n",
    "\n",
    "**Note: You can install and use the 'tqdm' library to help you track the process of your algorithm. Details are 'https://github.com/tqdm/tqdm'**\n",
    "\n",
    "**Note: It takes 30~60 min to execute the KNN algorithm.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4 1 9 2 1 3 4 3 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:48<00:00, 20.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101   0   1   0   0   0   0   0   1   0]\n",
      " [  1 119   3   3   2   0   1   6   6   0]\n",
      " [  1   1  85   1   0   0   0   0   1   0]\n",
      " [  0   0   0  90   0   3   0   0   4   0]\n",
      " [  0   0   0   0  79   0   0   0   0   1]\n",
      " [  0   0   0   1   0  87   0   0   2   2]\n",
      " [  2   0   1   0   1   0 114   0   0   0]\n",
      " [  0   0   3   0   0   1   0  99   1   1]\n",
      " [  0   0   0   0   0   0   0   0  73   0]\n",
      " [  0   0   0   0   2   1   0   1   5  93]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "from numpy import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "prediction_table=np.zeros((10,10), dtype=int)\n",
    "\n",
    "print(train_labels[:10])\n",
    "def knn(val_set_features,val_set_labels,train_set_features,train_set_labels,k):\n",
    "    prediction_table[:]=0 #reset\n",
    "    predict=\"\"\n",
    "    \n",
    "    for val_idx, vector in enumerate(tqdm(val_set_features)):\n",
    "        stored_arr=[]\n",
    "        for idx, trn_vector in enumerate(train_set_features):\n",
    "            dist=distance(vector,trn_vector) #get distance between the training set and the vector to identify the closest representation\n",
    "            stored_arr.append([dist,int(train_set_labels[idx])]) # store distance of euclidean distance between training vector and validation vector along with correspondint traiing label\n",
    "            #print(dist)\n",
    "        stored_arr.sort(key=lambda label: label[0]) #sort the array values based on the distance (input as a tuple at position 0)\n",
    "        k_freqs=[]\n",
    "        for num in range(k):\n",
    "            k_freqs.append(stored_arr[num][1]) #store labels that show up in k slots after sorting into k_freqs list to be counted\n",
    "        \n",
    "        count=Counter(k_freqs)#counts the number of occurences for each label in the top k range and stores the counts as a dictionary\n",
    "        predict=count.most_common(1)[0][0] #the prediction with the top number of counts out of k posssiblities\n",
    "        #print(f\"prediction was {predict} but truth was {val_set_labels[val_idx]}\")\n",
    "        prediction_table[predict,val_set_labels[val_idx]]+=1\n",
    "        \n",
    "def distance(test,train):\n",
    "    dist=np.sqrt(np.sum((test-train)**2))\n",
    "    return dist\n",
    "\n",
    "knn(validation_features[:1000],validation_labels[:1000],train_features[:5000],train_labels[:5000],10)\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(5, 5))   # single plot\n",
    "#ax.imshow(validation_features[2].reshape((28, 28)), cmap='gray')\n",
    "#ax.set_title(f\"Label is {validation_labels[2]}\")\n",
    "\n",
    "print(prediction_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, please write code to compute the **Accuracy**, and **Micro-averaged and Macro-averaged F1 scores** to evaluate the performance on the validation set.\n",
    "\n",
    "Print out these three metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101   0   1   0   0   0   0   0   1   0]\n",
      " [  1 119   3   3   2   0   1   6   6   0]\n",
      " [  1   1  85   1   0   0   0   0   1   0]\n",
      " [  0   0   0  90   0   3   0   0   4   0]\n",
      " [  0   0   0   0  79   0   0   0   0   1]\n",
      " [  0   0   0   1   0  87   0   0   2   2]\n",
      " [  2   0   1   0   1   0 114   0   0   0]\n",
      " [  0   0   3   0   0   1   0  99   1   1]\n",
      " [  0   0   0   0   0   0   0   0  73   0]\n",
      " [  0   0   0   0   2   1   0   1   5  93]]\n",
      "Accuracy is: 0.94\n",
      "[101 119  85  90  79  87 114  99  73  93]\n",
      "Macro F1: 0.9415450455674895\n",
      "Micro F1 is: 0.94\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(prediction_table)\n",
    "def accuracy():\n",
    "    total=np.sum(prediction_table)\n",
    "    tp=0\n",
    "    fn=0\n",
    "    fp=0\n",
    "    tn=0 # would just show up as a 0 in other categories other than the correct class for that row\n",
    "    \n",
    "    for idx, row in enumerate(prediction_table):\n",
    "        diagonal=idx\n",
    "        for col_idx,item in enumerate(row):\n",
    "            if(col_idx==diagonal):\n",
    "                #print(row[diagonal])\n",
    "                tp+=row[diagonal]\n",
    "            elif(col_idx!=diagonal):\n",
    "                fn+=row[col_idx]\n",
    "    print(f\"Accuracy is: {(tp+tn)/(total)}\")\n",
    "accuracy()#must follow knn\n",
    "\n",
    "#print(f\"Accuracy is: {(tp+tn)/(total)}\") #tn will just show up as a 0 for that row that discounts incorrect digits, so no need to add\n",
    "#print(f\"micro precision is {tp/(tp+fn)}\") #fn == fp in this clase because in this multiclass instance, if a value is not a diagonal it is both fp and fn\n",
    "\n",
    "#Macro Averaged \n",
    "#prints by column, need to sum up the scores and \n",
    "def f1_calc():\n",
    "    class_num=np.shape(prediction_table[0]) # could just use static 10\n",
    "    \n",
    "    macro_tp=np.diag(prediction_table)\n",
    "    print(macro_tp)\n",
    "    macro_fp=np.sum(prediction_table,axis=0)-macro_tp\n",
    "    macro_fn=np.sum(prediction_table, axis=1)-macro_tp\n",
    "    #print(macro_fp)\n",
    "    #print(macro_fn)\n",
    "    \n",
    "    macro_precision=(1/class_num[0])*np.sum(macro_tp/(macro_fp+macro_tp))\n",
    "    macro_recall = (1/class_num[0])*np.sum(macro_tp/(macro_fn+macro_tp))\n",
    "    #print(f\"Macro Precision is: {macro_precision}\")\n",
    "    macro_f1= (2*macro_precision*macro_recall) / (macro_precision + macro_recall)\n",
    "    print(f\"Macro F1: {macro_f1}\")\n",
    "    \n",
    "    # now for micro F1 score: (2* (precision)**2) / (2*Precision) --> precision\n",
    "    #Micro Averaged (sum up all tp)\n",
    "    #fp==fn so: micro precision==tp/tp+fp and micro recall ==tp/tp+fn, but fp==fn for micro\n",
    "    micro_tp=np.sum(macro_tp)\n",
    "    micro_fp=np.sum(macro_fp)\n",
    "    micro_fn=np.sum(macro_fn)\n",
    "    micro_precision=np.sum(micro_tp/(micro_tp+micro_fp))\n",
    "    micro_recall=np.sum(micro_tp/(micro_fn+micro_tp))\n",
    "    micro_f1= (2*micro_precision*micro_recall) / (micro_precision + micro_recall)\n",
    "    #print(f\"Micro Precision is: {micro_precision}\")\n",
    "    print(f\"Micro F1 is: {micro_f1}\")\n",
    "f1_calc()\n",
    "#print(f\"Micro Averaged: {micro_avg}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: PCA (30 points)\n",
    "\n",
    "In this part, you will implement the PCA algorithm to reduce the input dimension for the handwritten digit recognition task. In the next cell, please write your code to compute the transformation matrix in the PCA method for the training set we got from the previous part. Here, we only keep the **top 50 dimensions**.\n",
    "\n",
    "**Hint: You can use the function from the Numpy library to compute SVD:**\n",
    "\n",
    "*u, s, v = np.linalg.svd(a, full_matrices=False)*\n",
    "\n",
    "\n",
    "**Note: You should only use the training set to compute PCA without using validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "x=train_features.T\n",
    "x_bar= np.mean(x, axis=1, keepdims=True) #need to change to ensure it is the entire data set\n",
    "x_tilde=(x-x_bar) #new matrix witht he data centered ont he column mean\n",
    "\n",
    "u, s, v = np.linalg.svd(x_tilde,full_matrices=False)\n",
    "\n",
    "def dimension_reduce(start_features,p):#want it to take in a set, center it, and transform across train set, and project new features\n",
    "    y=start_features.T#represet train features\n",
    "    y_bar= np.mean(x, axis=1, keepdims=True)\n",
    "    y_tilde=(y-y_bar) #new matrix witht he data centered ont he column mean\n",
    "    \n",
    "    g_t=u[:,:p].T\n",
    "    z=g_t @ y_tilde\n",
    "    return z.T\n",
    "    \n",
    "\n",
    "#new matrix where we have educed to k features which will be useed int he KNN algorithm:\n",
    "p=50\n",
    "z_prime=dimension_reduce(train_features,p) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you need to apply the computed transformation matrix to reduce the dimension for the training set and the validation set. Then, build a new KNN model on the dimension-reduced training data and predict the labels for the dimension-reduced validation set. \n",
    "\n",
    "Print out the Accuracy, and Micro-averaged and Macro-averaged F1 scores.\n",
    "\n",
    "**Note: When you calculate the centered data for the validation set, you can calculate the mean feature values just by the validation data itself.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.77637915e+02  5.66348495e+01 -5.41226434e+02 ... -1.33110777e+01\n",
      "  -2.17161016e+01 -6.78769533e+01]\n",
      " [ 3.79159801e+02  5.22219114e-01 -7.76794560e+02 ...  3.17430675e+01\n",
      "   2.32006794e+00  2.06793510e+02]\n",
      " [ 8.58082886e+02 -1.28030364e+02  1.07925599e+02 ... -3.21390713e+01\n",
      "  -1.15855742e+02  2.35810938e+01]\n",
      " ...\n",
      " [-1.29732447e+03 -1.38038950e+02 -1.00245274e+03 ...  9.14259621e+01\n",
      "  -1.68360462e+01  2.07089653e+01]\n",
      " [ 1.12078392e+02 -7.74227098e+02 -1.34596030e+02 ...  1.72310960e+02\n",
      "   1.57752961e+01  3.10719605e+01]\n",
      " [-1.20486187e+03 -2.01268470e+01 -4.61925399e+02 ...  3.40105632e+01\n",
      "   1.35287180e+02  3.95822146e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:38<00:00, 26.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101   0   1   0   0   0   0   0   1   0]\n",
      " [  1 118   1   2   0   0   1   4   2   0]\n",
      " [  2   1  87   1   0   0   0   0   1   0]\n",
      " [  0   0   0  92   0   3   0   0   3   0]\n",
      " [  0   0   0   0  82   0   0   0   1   1]\n",
      " [  0   0   0   0   0  86   0   0   3   2]\n",
      " [  1   0   2   0   1   0 114   0   0   0]\n",
      " [  0   1   2   0   0   1   0 102   0   1]\n",
      " [  0   0   0   0   0   1   0   0  80   0]\n",
      " [  0   0   0   0   1   1   0   0   2  93]]\n",
      "Accuracy is: 0.955\n",
      "[101 118  87  92  82  86 114 102  80  93]\n",
      "Macro F1: 0.9549687930757028\n",
      "Micro F1 is: 0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "val_prime=dimension_reduce(validation_features,p)\n",
    "\n",
    "\n",
    "#y=validation_features.T\n",
    "#y_bar= np.mean(y, axis=1, keepdims=True) #need to change to ensure it is the entire data set\n",
    "    \n",
    "#y_tilde=(y-y_bar)\n",
    "    \n",
    "#val_prime=(g_t @ y_tilde).T # val_prime represents the new matrix with 3000 rows(objexts) and 50 features \n",
    "    #print(z[0:5,0:5])\n",
    "\n",
    "#implement KNN\n",
    "knn(val_prime[:1000],validation_labels[:1000],z_prime[:5000],train_labels[:5000],7)\n",
    "print(prediction_table)\n",
    "accuracy()\n",
    "f1_calc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Tune Hyperparameter (20 points)\n",
    "\n",
    "In this part, you need to do your best to tune the hyperparameters in KNN and PCA to build the best model.\n",
    "\n",
    "You should tune three hyperparameters with the training data provided:\n",
    "\n",
    "- the number of nearest neighbors in KNN \n",
    "- the distance measurement (choose from Euclidean distance, L1 norm distance, and cosine distance)\n",
    "- the number of dimensions kept in PCA \n",
    "\n",
    "\n",
    "**Hint: You can tune these hyperparameters by one randomly generated validation set (like what you have done in previous parts), or you can also use the cross-validation method.**\n",
    "\n",
    "**Hint: To save your time, you can subsample 50% (or even less) of the training data to tune hyperparameters.**\n",
    "\n",
    "**Note: For each hyperparameter, you must try at least 2 different values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What is your final hyperparameter setting? How do you tune them? What choices have you tried?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test if your best hyperparameter setting really works. We will load a separate testing dataset to test your choice. Let's load the testing data by executing the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array of testing feature matrix: shape (10000, 784)\n",
      "array of testing labels: shape (10000,)\n"
     ]
    }
   ],
   "source": [
    "test_features = np.loadtxt(\"test.txt\", delimiter=',')\n",
    "test_labels = np.loadtxt(\"test_label.txt\")\n",
    "print('array of testing feature matrix: shape ' + str(np.shape(test_features)))\n",
    "print('array of testing labels: shape ' + str(np.shape(test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please apply the KNN model with the best hyperparameter setting you find above to this testing set, and report the Accuracy, and Micro-averaged and Macro-averaged F1 scores of your best model on the testing set.\n",
    "\n",
    "Print out these three metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
